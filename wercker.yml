box:
  id: node:6
  ports: # decide which port to expose to host
    - "3000"

# wercker dev --expose-ports=true
dev: #NODE_ENV=development
  box:
    id: node:6
    ports:
      - "3000"  # nodejs port
      - "1337"  # chrome UI for debugging
      - "5858"  # port for node-inspector debugging socket
  steps:
    - npm-install
    # you have two options for local development
    # # 1. Run in local development debugging mode. auto re-run on files changes
    - script:
        name: start dev environment
        code: npm run dev:debug

    # # 2. run in BDD mode. auto re-run test cases on file changes
    # - script:
    #     name: start bdd environment
    #     code: npm run bdd

# wercker build
build: #NODE_ENV=development
  steps:
    - npm-install
    - npm-test
    # uncomment the following to enable docker image creation to docker hub
    # - internal/docker-push:
    #     disable-sync: true
    #     username: $DOCKER_USERNAME  # replace DOCKER_USERNAME with your docker hub user name
    #     password: $DOCKER_PASSWORD  # replace DOCKER_PASSWORD with your docker hub password
    #     repository: $DOCKER_REPO # replace DOCKER_REPO with your docker hub registries name. eg: sample-svc
    #     working-dir: $WERCKER_SOURCE_DIR
    #     entrypoint: gulp dev --debug
    #     tag: debug-build
    #     ports:
    #        - "3000"  # nodejs port
    #        - "1337"  # chrome UI for debugging
    #        - "5858"  # port for node-inspector debugging socket

fetch-env-provisioner:
  steps:
    # load $MASTER_S3_CONFIG from wercker dashboard
    # will fallback to default values provided in config/container_env/master.s3.config if it exists
    - script:
        name: read s3 config for wercker
        code: |
          if [ -f "config/container_env/master.s3.config" ]; then
            MASTER_S3_CONFIG="$(echo "$(cat config/container_env/master.s3.config | base64)")"
          fi
          MASTER_S3_CONFIG_CSV=$(echo "$MASTER_S3_CONFIG" | base64 --decode)
          MASTER_S3_CONFIG_ACCESS_KEY_ID=${MASTER_S3_CONFIG_ACCESS_KEY_ID=$(echo $MASTER_S3_CONFIG_CSV | cut -d "," -f 1)}
          MASTER_S3_CONFIG_SECRET_ACCESS_KEY=${MASTER_S3_CONFIG_SECRET_ACCESS_KEY=$(echo $MASTER_S3_CONFIG_CSV | cut -d "," -f 2)}
          MASTER_S3_CONFIG_REGION=${MASTER_S3_CONFIG_REGION=$(echo $MASTER_S3_CONFIG_CSV | cut -d "," -f 3)}
          MASTER_S3_CONFIG_BUCKET=${MASTER_S3_CONFIG_BUCKET=$(echo $MASTER_S3_CONFIG_CSV | cut -d "," -f 4)}
          MASTER_S3_CONFIG_ENV_SH=${MASTER_S3_CONFIG_ENV_SH=$(echo $MASTER_S3_CONFIG_CSV | cut -d "," -f 5)}
    # download the env-provisioner.sh from s3 using the configuration from the above $MASTER_S3_CONFIG
    - arjen/s3get:
        access_key: $MASTER_S3_CONFIG_ACCESS_KEY_ID
        secret_key: $MASTER_S3_CONFIG_SECRET_ACCESS_KEY
        bucket: $MASTER_S3_CONFIG_BUCKET
        key: $MASTER_S3_CONFIG_ENV_SH
        region: $MASTER_S3_CONFIG_REGION
        filename: $WERCKER_CACHE_DIR/env-provisioner.sh

# optional step to generate api docs and test coverage report
update-doc:
  box:
    id: axnux/swagger2aglio:latest
  steps:
    # expose the environment variables provided in env-provisioner.sh
    - script:
        name: read environment variables from default env vars files
        code: source $WERCKER_CACHE_DIR/env-provisioner.sh
    - script:
        name: generate api doc
        code: swagger2aglio --theme-variables slate --input ./docs/api.yml --output ./docs/api_doc/api.html
    - s3sync: # synchronize api docs and test coverage report to s3
        source_dir: ./docs/
        delete_removed: true
        bucket_url: $S3_TEST_REPORT_BUCKET_URL/$WERCKER_GIT_REPOSITORY/$WERCKER_MAIN_PIPELINE_STARTED-$WERCKER_GIT_COMMIT/ # eg: s3://bucket-name/ # make sure the trailing '/' is always there
        key_id: $S3_TEST_REPORT_ACCESS_KEY_ID
        key_secret: $S3_TEST_REPORT_SECRET_ACCESS_KEY

docker:
  box:
    id: axnux/node-gulp:latest
  steps:
    # expose the environment variables provided in env-provisioner.sh
    - script:
        name: read environment variables from default env vars files
        code: source $WERCKER_CACHE_DIR/env-provisioner.sh
    # push to docker hub
    - internal/docker-push:
        disable-sync: true
        username: $DOCKER_USERNAME  # define DOCKER_USERNAME in your wercker dashboard
        password: $DOCKER_PASSWORD  # define DOCKER_PASSWORD in your wercker dashboard
        working-dir: $WERCKER_SOURCE_DIR
        env: |
          NODE_ENV=development
          S3_ACCESS_KEY_ID=$TEMPLATE_AWS_S3_KEY_ID
          S3_SECRET_ACCESS_KEY=$TEMPLATE_AWS_S3_SECRET_ACCESS_KEY
          S3_REGION=$TEMPLATE_AWS_S3_REGION
          S3_BUCKET=$TEMPLATE_AWS_S3_BUCKET
          UPLOAD_DIR=$TEMPLATE_UPLOAD_DIR
        entrypoint: gulp dev --debug
        tag: development
        repository: $DOCKER_REPO
        author: axnux

    # push to AWS ECR
    # - internal/docker-push:
    #     disable-sync: true
    #     aws-access-key: $AWS_ECR_ACCESS_KEY_ID
    #     aws-secret-key: $AWS_ECR_SECRET_ACCESS_KEY
    #     aws-region: $AWS_ECR_REGION
    #     aws-registry-id: $AWS_ECR_REGISTRY_ID
    #     working-dir: $WERCKER_SOURCE_DIR
    #     env: |
    #       NODE_ENV=development
    #       S3_ACCESS_KEY_ID=$TEMPLATE_AWS_S3_KEY_ID
    #       S3_SECRET_ACCESS_KEY=$TEMPLATE_AWS_S3_SECRET_ACCESS_KEY
    #       S3_REGION=$TEMPLATE_AWS_S3_REGION
    #       S3_BUCKET=$TEMPLATE_AWS_S3_BUCKET
    #       UPLOAD_DIR=$TEMPLATE_UPLOAD_DIR
    #     entrypoint: /usr/local/bin/node server.js
    #     tag: development
    #     repository: template-svc
    #     author: axnux

### release workflow ###
build-production: #NODE_ENV=production
  steps:
    # expose the environment variables provided in env-provisioner.sh
    - script:
        name: read environment variables from default env vars files
        code: source $WERCKER_CACHE_DIR/env-provisioner.sh
    - script:
        name: clean npm modules
        code: rm -rf node_modules/*
    - npm-install
    - npm-test
    - script:
        name: set to production environment
        code: export NODE_ENV=production
    - script:
        name: release build
        code: npm run release:build
    - script:
        name: npm prune
        code: npm prune
    - script:
        name: list node_modules
        code: ls ./node_modules
    - script: # TODO static build nodejs
        name: copy files
        code: |
          cp $(which node) "$WERCKER_OUTPUT_DIR"
          rm -rf ./node_modules/.bin
          cp -RL ./node_modules ./src ./deploy ./config ./tmp ./server.js ./package.json "$WERCKER_OUTPUT_DIR"

docker-production:
  box:
    id: node:6-slim
  steps:
    # expose the environment variables provided in env-provisioner.sh
    - script:
        name: read environment variables from default env vars files
        code: source $WERCKER_CACHE_DIR/env-provisioner.sh
    # push to docker hub
    - internal/docker-push:
        disable-sync: true
        username: $DOCKER_USERNAME  # define DOCKER_USERNAME in your wercker dashboard
        password: $DOCKER_PASSWORD  # define DOCKER_PASSWORD in your wercker dashboard
        working-dir: $WERCKER_SOURCE_DIR
        env: |
          NODE_ENV=production
          S3_ACCESS_KEY_ID=$TEMPLATE_AWS_S3_KEY_ID
          S3_SECRET_ACCESS_KEY=$TEMPLATE_AWS_S3_SECRET_ACCESS_KEY
          S3_REGION=$TEMPLATE_AWS_S3_REGION
          S3_BUCKET=$TEMPLATE_AWS_S3_BUCKET
          UPLOAD_DIR=$TEMPLATE_UPLOAD_DIR
        cmd: ./node ./server.js
        tag: production
        repository: $DOCKER_REPO
        author: axnux

    # push to AWS ECR
    # - internal/docker-push:
    #     disable-sync: true
    #     aws-access-key: $AWS_ECR_ACCESS_KEY_ID
    #     aws-secret-key: $AWS_ECR_SECRET_ACCESS_KEY
    #     aws-region: $AWS_ECR_REGION
    #     aws-registry-id: $AWS_ECR_REGISTRY_ID
    #     working-dir: $WERCKER_SOURCE_DIR
    #     env: |
    #       NODE_ENV=production
    #       S3_ACCESS_KEY_ID=$TEMPLATE_AWS_S3_KEY_ID
    #       S3_SECRET_ACCESS_KEY=$TEMPLATE_AWS_S3_SECRET_ACCESS_KEY
    #       S3_REGION=$TEMPLATE_AWS_S3_REGION
    #       S3_BUCKET=$TEMPLATE_AWS_S3_BUCKET
    #       UPLOAD_DIR=$TEMPLATE_UPLOAD_DIR
    #     cmd: ./node ./server.js
    #     tag: production
    #     repository: template-svc
    #     author: axnux

  # after-steps: # send notification to slack
  #   - slack-notifier:
  #       url: $SLACK_WEB_HOOK
  #       channel: updates
  #       username: Wercker Bot
  #       notify_on: failed


# if you are launching your kubernetes stack with kube-aws
# you already have all the necessary pem files in place
k8s-deploy:
  box:
    id: axnux/alpine-aws-ecr:latest # has built in aws cli & kubectl
  steps:
    # expose the environment variables provided in env-provisioner.sh
    - script:
        name: read environment variables from default env vars files
        code: source $WERCKER_CACHE_DIR/env-provisioner.sh
    - script:
        name: set deploy image repository
        code: DEPLOY_IMAGE_REPO=${DEPLOY_IMAGE_REPO="$DOCKER_USERNAME/$DOCKER_REPO"}
    - script:
      name: download files for kubernetes
      code: |
        AWS_ACCESS_KEY_ID=$S3_ACCESS_KEY_FOR_KUBERNETES AWS_SECRET_ACCESS_KEY=$S3_SECRET_KEY_FOR_KUBERNETES AWS_DEFAULT_REGION=$S3_REGION_FOR_KUBERNETES \
          aws s3 cp s3://$S3_BUCKET_FOR_KUBERNETES deploy --recursive
    - xun91/bash-templater:
      template: deploy/service-template.yml
      output: deploy/zap.yml
      # anything that is declared here will be available as parameters in servie-template.yml file
      parameters:
        GIT_COMMIT_HASH=$WERCKER_GIT_COMMIT
        AWS_ECR_ID=$AWS_ECR_REGISTRY_ID
        AWS_ECR_REGION=$AWS_ECR_REGION
        DEPLOY_IMAGE_REPO=$DEPLOY_IMAGE_REPO
        DEPLOY_IMAGE_TAG=$DEPLOY_IMAGE_TAG
        DEPLOY_IMAGE_PULL_SECRET=$DEPLOY_IMAGE_PULL_SECRET
        DEPLOY_SERVICE_PORT=$DEPLOY_SERVICE_PORT
        TEMPLATE_SERVICE_UPLOAD_DIR=$TEMPLATE_UPLOAD_DIR
    - script:
      name: print deployment file
      code: cat deploy/zap.yml
    # workaround
    # https://github.com/whereisaaron/kubernetes-aws-scripts/blob/master/create-ecr-imagepullsecret.sh
    # uncomment this only if you are using AWS ECR
    # - script:
    #   name: generate docker config secret
    #   code: |
    #     AWS_AUTH_TOKEN=`AWS_ACCESS_KEY_ID=$AWS_ECR_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$AWS_ECR_SECRET_ACCESS_KEY AWS_DEFAULT_REGION=$AWS_ECR_REGION aws ecr --region=$AWS_ECR_REGION get-authorization-token --output text --query authorizationData[].authorizationToken | base64 -d | cut -d: -f2`
    #     export AWS_ECR_AUTH_TOKEN=$AWS_AUTH_TOKEN
    # - script:
    #   name: generate secret for kubernetes
    #   command: |
    #     kubectl --server="$KUBERNETES_MASTER" \
    #       --certificate-authority="deploy/ca.pem" \
    #       --client-certificate="deploy/admin.pem" \
    #       --client-key="deploy/admin-key.pem" \
    #       delete secret --ignore-not-found $DEPLOY_IMAGE_PULL_SECRET
    #     kubectl --server="$KUBERNETES_MASTER" \
    #       --certificate-authority="deploy/ca.pem" \
    #       --client-certificate="deploy/admin.pem" \
    #       --client-key="deploy/admin-key.pem" \
    #       create secret docker-registry $DEPLOY_IMAGE_PULL_SECRET \
    #        --docker-server=https://$AWS_ECR_REGISTRY_ID.dkr.ecr.$AWS_ECR_REGION.amazonaws.com \
    #        --docker-username=AWS \
    #        --docker-password="$AWS_ECR_AUTH_TOKEN" \
    #        --docker-email=""
    - kubectl:
      server: $KUBERNETES_MASTER
      certificate-authority: deploy/ca.pem
      client-certificate: deploy/admin.pem
      client-key: deploy/admin-key.pem
      command: apply -f deploy/zap.yml

# optional slack notifier
# after-steps: # send notification to slack
#   - slack-notifier:
#       url: $SLACK_WEB_HOOK
#       channel: updates
#       username: Wercker Bot
